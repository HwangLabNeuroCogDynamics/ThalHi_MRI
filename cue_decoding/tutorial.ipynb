{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to run 3dlss on the chosen subjects. An example bash script is shown in the ThalHi scripts directory at 3dlss. Change the subjects and model as needed. The output files will be the cue name followed by .LSS+tlrc.BRIK and .HEAD. To work with this data, we will convert it to a more managable data object next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your LSS data you can convert it to a data object for easier manipulation.\n",
    "From the decoding.py file import the SubjectLssTentData class and instantiate by passing the subject deconvolve directory and list of cues you are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ThalHi_MRI.decoding import SubjectLssTentData\n",
    "\n",
    "CUES = [\"dcb\", \"fcb\", \"dpb\", \"fpb\", \"dcr\", \"fcr\", \"dpr\", \"fpr\"]\n",
    "deconvolve_sub_dir = \"/data/backed_up/shared/ThalHi_MRI_2020/3dDeconvolve/sub-10001\"\n",
    "lss_tent = SubjectLssTentData(deconvolve_sub_dir, CUES) # tent length and path to save object at are optional arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the object automatically converts the lss files into a numpy array in the shape of [voxel_x, voxel_y, voxel_z, tent_length * num_trials] where the last dimension is the tent length multiplied by the number of trials. For example, with a tent length of 9, the first trial and first tent would be index 0, the 1st trial and 2nd tent would be index 1 ... and the 9th tent would be 8. Then, the second trial would then start at index 9 and continue the same pattern. So it goes.\n",
    "\n",
    "Additionally, the object creates an average of the tents for each trial, which is stored in another numpy array in the shape of [voxel_x, voxel_y, voxel_z, num_trials].\n",
    "\n",
    "Finally, the object removes all nan trials (censored) from both matrices and saves (via pickle) the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access the trials with all the tents via the .data property\n",
    "print(lss_tent.data)\n",
    "print(lss_tent.data.shape)\n",
    "\n",
    "# You can access the averaged tents per trial via the .avg_data property\n",
    "print(lss_tent.avg_data)\n",
    "print(lss_tent.avg_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make changes to the object and then save them using the .save() function. The path is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lss_tent.save(\"new_lss_data.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have previously created your object and saved it. You can load it by using the static load function and passing the filepath. This will load the object and you can use the same functions and access the same properties as previously discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lss_tent = SubjectLssTentData.load(\"path_to_lss/lss.p\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "name": "python370jvsc74a57bd05360a8a1268f096c13c8df890fc4a16c0167eeb01ca5fdbdc6c7f6464813bd70"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "5360a8a1268f096c13c8df890fc4a16c0167eeb01ca5fdbdc6c7f6464813bd70"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}